# 応用数学レポート
下記の要件の通り、区分ごとに単元レポートを作成、ご提出ください。
<br> １）各章につき100文字以上で要点をまとめ、実装演習結果、確認テストについての自身の考察等を取り入れたレポートとする。
<br> ２）各科目の基準点が足りない場合、実装演習が不足する場合は差し戻しとする。
<br> ※各章は講義動画および講義資料（PDF）でご確認ください。

## 第１章：線形代数
前半で行列の基本的な演算について学び、行列版の逆数である逆行列の求め方（行列式が０となる行列については存在しない）も学んだ。
<br> 後半は、固有値・固有ベクトルの計算方法について学んだ。
<br> 特に、正方行列以外の行列についての固有値分解（特異値分解）については個人的に初めて知り、画像について応用例があることを学んだ。
<br> 確認テストでも、特異値分解についての出題があり、必ず計算を抑えておきたいと感じた。

## 第２章：確率・統計
確率変数・確率分布や期待値・分散・共分散など確率に関する基本的な性質について学んだ。
<br> 確率分布にもさまざま存在し、ベルヌーイ分布、二項分布、ガウス分布について学んだ。
<br> 確認テストでは、離散確率分布における期待値の定義の出題があった、基本的ではあるが、連続関数の場合と異なることに改めて注意したいと思った。
<br> また、ベルヌーイ分布の期待値・分散についての出題もあり、基本的な分布の期待値、分散等は計算できることはもちろん結果自体を覚えておきたいと感じた。

## 第３章：情報理論
前半では、自己情報量・シャノンエントロピーの定義について学んだ。
<br> ある事象に対しての（自己）情報量を、
<br> ・確率が低いことほど情報量が多いことを表現したい。
<br> ・情報量について加法性を持たせたい。
<br> という直感的な部分と数学的な要請も考慮して、
<br> ある事象が起こる確率pに対して、-log p（底はなんでも良く、本質的な問題ではない）と定義している。
<br> また、シャノンエントロピーを自己情報量の期待値として定義している。
<br> 
<br> なお、情報量に関する用語については統一的でなく、
<br> 自己情報量のことを選択情報量や単に情報量と呼んだり、
<br> シャノンエントロピーのことを平均情報量や単に情報量やエントロピーと呼んだりする。
<br> 混同しやすいので文脈により判断していく必要がありそうだ。
<br> 
<br> 後半では、KLダイバージェンスと交差エントロピーとの関係などを学習した。
<br> KLダイバージェンスは２つの確率分布の自己情報量の差の期待値を定義としており、
<br> また、分布qのpに対する交差エントロピーを、H(p,q)= -Σp(x)log q(x)（離散の場合）と定義する。
<br> ここで、交差エントロピーとKLダイバージェンスは、分布が逆転すると意味が変わるため、どの分布からどの分布へのものか注意が必要である。
<br> 確率分布Q(x)のP(x)に対する交差エントロピーは、P(x)のシャノンエントロピーとP(x)からQ(x)のKLダイバージェンスの和と等しいという性質がある。
<br> なお、P(x)とQ(x)が等しい場合には、KLダイバージェンスは0となる。
